#!/usr/bin/env python3
"""
Teste das melhorias crÃ­ticas implementadas com base na anÃ¡lise do Gemini
"""

import asyncio
import sys
from pathlib import Path

# Adiciona o diretÃ³rio do projeto ao path
sys.path.insert(0, str(Path(__file__).parent))

async def test_critical_improvements():
    """Testa as melhorias crÃ­ticas implementadas"""
    print("ğŸ§ª Testando Melhorias CrÃ­ticas Implementadas")
    print("=" * 50)
    
    results = {}
    
    # 1. Teste de ConfiguraÃ§Ã£o de Thresholds Ajustados
    print("\n1. ğŸ¯ Testando ConfiguraÃ§Ã£o de Thresholds Ajustados...")
    try:
        from gemini_code.analysis.health_monitor import HealthMonitor
        from gemini_code.core.gemini_client import GeminiClient
        from gemini_code.core.file_manager import FileManagementSystem
        
        # Criar instÃ¢ncias sem executar anÃ¡lise completa
        print("   â€¢ Inicializando HealthMonitor...")
        gemini_client = GeminiClient()
        file_manager = FileManagementSystem(gemini_client)
        health_monitor = HealthMonitor(gemini_client, file_manager)
        
        config = health_monitor.monitoring_config
        
        # Verificar se os thresholds foram ajustados
        expected_adjustments = {
            'error_threshold': 3,
            'test_coverage_threshold': 60.0,
            'code_quality_threshold': 6.0,
            'documentation_threshold': 50.0
        }
        
        all_adjusted = True
        for key, expected_value in expected_adjustments.items():
            actual_value = config[key]
            if actual_value == expected_value:
                print(f"   âœ… {key}: {actual_value} (ajustado corretamente)")
            else:
                print(f"   âŒ {key}: {actual_value} (esperado: {expected_value})")
                all_adjusted = False
        
        # Verificar padrÃµes de exclusÃ£o
        if 'excluded_patterns' in config and len(config['excluded_patterns']) > 0:
            print(f"   âœ… PadrÃµes de exclusÃ£o configurados: {len(config['excluded_patterns'])} padrÃµes")
        else:
            print("   âŒ PadrÃµes de exclusÃ£o nÃ£o configurados")
            all_adjusted = False
        
        results['thresholds_adjusted'] = all_adjusted
        
    except Exception as e:
        print(f"   âŒ Erro no teste de thresholds: {e}")
        results['thresholds_adjusted'] = False
    
    # 2. Teste de ValidaÃ§Ã£o de Entrada Robusta
    print("\n2. ğŸ›¡ï¸ Testando ValidaÃ§Ã£o de Entrada Robusta...")
    try:
        from gemini_code.core.nlp_enhanced import NLPEnhanced
        
        nlp = NLPEnhanced()
        
        # Teste com entrada vazia
        result_empty = await nlp.identify_intent("")
        if result_empty['intent'] == 'unknown' and result_empty['confidence'] == 0:
            print("   âœ… Entrada vazia tratada corretamente")
        else:
            print(f"   âŒ Entrada vazia nÃ£o tratada: {result_empty}")
        
        # Teste com entrada apenas espaÃ§os
        result_spaces = await nlp.identify_intent("   \n\t   ")
        if result_spaces['intent'] == 'unknown':
            print("   âœ… Entrada com apenas espaÃ§os tratada corretamente")
        else:
            print(f"   âŒ Entrada com espaÃ§os nÃ£o tratada: {result_spaces}")
        
        # Teste com entrada muito longa
        long_text = "a" * 6000
        result_long = await nlp.identify_intent(long_text)
        if result_long is not None:
            print("   âœ… Entrada muito longa tratada sem erro")
        else:
            print("   âŒ Entrada muito longa causou erro")
        
        results['input_validation'] = True
        
    except Exception as e:
        print(f"   âŒ Erro no teste de validaÃ§Ã£o: {e}")
        results['input_validation'] = False
    
    # 3. Teste de Filtros de Arquivos Melhorados
    print("\n3. ğŸ“ Testando Filtros de Arquivos Melhorados...")
    try:
        health_monitor = HealthMonitor(gemini_client, file_manager)
        
        # Testar filtro de arquivos
        valid_files = health_monitor._filter_valid_python_files(str(Path.cwd()))
        
        print(f"   â€¢ Arquivos Python vÃ¡lidos encontrados: {len(valid_files)}")
        
        # Verificar se __pycache__ foi filtrado
        has_pycache = any('__pycache__' in str(f) for f in valid_files)
        if not has_pycache:
            print("   âœ… Arquivos __pycache__ filtrados corretamente")
        else:
            print("   âŒ Arquivos __pycache__ nÃ£o foram filtrados")
        
        # Verificar se arquivos temporÃ¡rios foram filtrados
        has_temp = any('temp_' in str(f) or f.name.startswith('.') for f in valid_files)
        if not has_temp:
            print("   âœ… Arquivos temporÃ¡rios filtrados corretamente")
        else:
            print("   âš ï¸ Alguns arquivos temporÃ¡rios podem nÃ£o ter sido filtrados")
        
        results['file_filtering'] = len(valid_files) > 0 and not has_pycache
        
    except Exception as e:
        print(f"   âŒ Erro no teste de filtros: {e}")
        results['file_filtering'] = False
    
    # 4. Teste de HumanizaÃ§Ã£o de Erros
    print("\n4. ğŸ’¬ Testando HumanizaÃ§Ã£o de Erros...")
    try:
        from gemini_code.utils.error_humanizer import humanize_error
        
        # Teste com erro comum
        test_error = FileNotFoundError("No such file or directory: 'arquivo.py'")
        humanized = humanize_error(test_error, "Teste de erro")
        
        if "âŒ" in humanized and "ğŸ’¡" in humanized:
            print("   âœ… Erro humanizado corretamente com emojis e dicas")
        else:
            print(f"   âŒ Erro nÃ£o humanizado adequadamente: {humanized[:100]}...")
        
        # Teste com erro de API
        api_error = AttributeError("'NoneType' object has no attribute 'generate_response'")
        humanized_api = humanize_error(api_error, "ComunicaÃ§Ã£o com IA")
        
        if "comunicaÃ§Ã£o" in humanized_api.lower() or "problema interno" in humanized_api.lower():
            print("   âœ… Erro de API humanizado corretamente")
        else:
            print("   âŒ Erro de API nÃ£o humanizado adequadamente")
        
        results['error_humanization'] = True
        
    except Exception as e:
        print(f"   âŒ Erro no teste de humanizaÃ§Ã£o: {e}")
        results['error_humanization'] = False
    
    # 5. Teste de Estrutura do Projeto
    print("\n5. ğŸ“‚ Testando Melhorias na Estrutura do Projeto...")
    try:
        project_root = Path.cwd()
        
        # Verificar se .gitignore foi criado
        gitignore_exists = (project_root / '.gitignore').exists()
        if gitignore_exists:
            print("   âœ… Arquivo .gitignore criado")
        else:
            print("   âŒ Arquivo .gitignore nÃ£o encontrado")
        
        # Verificar se error_humanizer foi criado
        humanizer_exists = (project_root / 'gemini_code' / 'utils' / 'error_humanizer.py').exists()
        if humanizer_exists:
            print("   âœ… Error humanizer implementado")
        else:
            print("   âŒ Error humanizer nÃ£o encontrado")
        
        results['project_structure'] = gitignore_exists and humanizer_exists
        
    except Exception as e:
        print(f"   âŒ Erro no teste de estrutura: {e}")
        results['project_structure'] = False
    
    # RelatÃ³rio Final
    print("\n" + "=" * 50)
    print("ğŸ“Š RELATÃ“RIO FINAL DOS TESTES")
    print("=" * 50)
    
    passed = 0
    total = len(results)
    
    for test_name, passed_test in results.items():
        status = "âœ… PASSOU" if passed_test else "âŒ FALHOU"
        test_display = {
            'thresholds_adjusted': 'ConfiguraÃ§Ã£o de Thresholds Ajustados',
            'input_validation': 'ValidaÃ§Ã£o de Entrada Robusta', 
            'file_filtering': 'Filtros de Arquivos Melhorados',
            'error_humanization': 'HumanizaÃ§Ã£o de Erros',
            'project_structure': 'Melhorias na Estrutura do Projeto'
        }
        print(f"{status} - {test_display.get(test_name, test_name)}")
        if passed_test:
            passed += 1
    
    print(f"\nğŸ† Resultado: {passed}/{total} melhorias crÃ­ticas implementadas com sucesso")
    
    if passed == total:
        print("ğŸ‰ Todas as melhorias crÃ­ticas estÃ£o funcionando!")
        print("ğŸš€ O projeto agora deve ter um score de saÃºde muito melhor!")
        return 0
    else:
        print("âš ï¸ Algumas melhorias crÃ­ticas precisam de ajustes.")
        return 1

if __name__ == "__main__":
    try:
        exit_code = asyncio.run(test_critical_improvements())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\nğŸ›‘ Testes interrompidos pelo usuÃ¡rio")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ Erro crÃ­tico nos testes: {e}")
        sys.exit(1)
